{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import Dataset, DatasetDict\n",
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and clean \n",
    "# Data is from https://www.kaggle.com/datasets/arshkandroo/behavioural-tweets?select=Lonely_Tweets.csv.\n",
    "# Tweepy API was used to scrape twitter for lonely and normal tweets. The quality is okay but \n",
    "# some misclassification. The tweets are already cleaned using the NLTK library according to the\n",
    "# data collectors.\n",
    "\n",
    "# The downloaded data from Kaggle was saved in a corrupted way with both csv.xls endings.\n",
    "# I used os to save them as pure csv files first. The files also contained bad first (index) \n",
    "# columns, requiring different ways of dropping these columns.\n",
    "\n",
    "df_normal = pd.read_csv('Data/Normal_Tweets.csv', index_col=0)\n",
    "df_normal.columns.values[0] = 'tweet'\n",
    "df_normal['label'] = 0                                  # 0 for normal tweets \n",
    "\n",
    "df_lonely = pd.read_csv('Data/Lonely_Tweets.csv', usecols=lambda column: column != 'Unnamed: 0')\n",
    "df_lonely.columns.values[0] = 'tweet'\n",
    "df_lonely['label'] = 1                                  # 1 for lonely tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a crudely filtered dataset. The quality of the uploaded data is low\n",
    "# and this creates large, fluctuating losses for the model training later. \n",
    "\n",
    "keywords = [\"alone\", \"lonely\", \"no one\"]\n",
    "filtered_df = df_lonely[df_lonely['tweet'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "df = pd.concat([df_normal, filtered_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set has 11240 tweets in it.\n",
      "\n",
      "There are 2 variables and they are as follows: \n",
      "tweet    object\n",
      "label     int64\n",
      "dtype: object\n",
      "\n",
      "The first and last five rows of the table are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>remember hillary email non secure server</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cant avoid demon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>por fin la pusieron en spotify losing way de f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kills</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thank introduce important gunsense law make co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8504</th>\n",
       "      <td>love realize day dont want bother nothing wron...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8507</th>\n",
       "      <td>hi kerry believe alone please know thousand pe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>even though mean gotta let go yeah dependent y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>claire please message ever need talk lonely</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8519</th>\n",
       "      <td>lrt leave alone finally found need cry love ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  label\n",
       "0             remember hillary email non secure server       0\n",
       "1                                     cant avoid demon       0\n",
       "2     por fin la pusieron en spotify losing way de f...      0\n",
       "3                                                kills       0\n",
       "4     thank introduce important gunsense law make co...      0\n",
       "8504  love realize day dont want bother nothing wron...      1\n",
       "8507  hi kerry believe alone please know thousand pe...      1\n",
       "8513  even though mean gotta let go yeah dependent y...      1\n",
       "8514       claire please message ever need talk lonely       1\n",
       "8519  lrt leave alone finally found need cry love ha...      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display summary data\n",
    "print(f\"The data set has {len(df)} tweets in it.\")\n",
    "print()\n",
    "\n",
    "print(f\"There are {df.shape[1]} variables and they are as follows: \")\n",
    "print(df.dtypes)\n",
    "print()\n",
    "\n",
    "print(\"The first and last five rows of the table are:\")\n",
    "pd.concat([df.head(), df.tail()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data intoa a dataset file and spplit into \n",
    "# training and validation set\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.remove_columns(['__index_level_0__'])\n",
    "train_test_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "test_valid_split = train_test_split['test'].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "final_dataset = DatasetDict({\n",
    "    'train': train_test_split['train'],\n",
    "    'test': test_valid_split['test'],\n",
    "    'validation': test_valid_split['train']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ff02825ebf4708856da29a8ec949ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8992 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0896525335242768cd676df5cda8be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a26757a8a5246dab5120d24bbcdb8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['tweet'], truncation=True, padding='max_length', max_length=20)\n",
    "\n",
    "tokenized_dataset = final_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "os.makedirs('./logs', exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    log_level=\"error\"\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'], \n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18811ab6d5674123bb92d81ace89e296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3901, 'grad_norm': 1.4290518760681152, 'learning_rate': 4.955516014234875e-05, 'epoch': 0.02}\n",
      "{'loss': 0.3932, 'grad_norm': 3.893188238143921, 'learning_rate': 4.911032028469751e-05, 'epoch': 0.04}\n",
      "{'loss': 0.3823, 'grad_norm': 3.055434465408325, 'learning_rate': 4.8665480427046265e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1893, 'grad_norm': 1.3895586729049683, 'learning_rate': 4.822064056939502e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0595, 'grad_norm': 4.644923210144043, 'learning_rate': 4.777580071174377e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0732, 'grad_norm': 0.07944002002477646, 'learning_rate': 4.733096085409253e-05, 'epoch': 0.11}\n",
      "{'loss': 0.079, 'grad_norm': 3.657280683517456, 'learning_rate': 4.6886120996441285e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0409, 'grad_norm': 0.07090166956186295, 'learning_rate': 4.644128113879004e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0702, 'grad_norm': 0.13260957598686218, 'learning_rate': 4.599644128113879e-05, 'epoch': 0.16}\n",
      "{'loss': 0.1202, 'grad_norm': 2.410168170928955, 'learning_rate': 4.555160142348754e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1596, 'grad_norm': 2.7050256729125977, 'learning_rate': 4.5106761565836305e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0641, 'grad_norm': 0.18941017985343933, 'learning_rate': 4.4661921708185054e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0583, 'grad_norm': 0.17160263657569885, 'learning_rate': 4.421708185053381e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0982, 'grad_norm': 0.08361107110977173, 'learning_rate': 4.377224199288256e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0893, 'grad_norm': 4.408141136169434, 'learning_rate': 4.3327402135231324e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0266, 'grad_norm': 0.030027778819203377, 'learning_rate': 4.2882562277580074e-05, 'epoch': 0.28}\n",
      "{'loss': 0.1912, 'grad_norm': 1.9034544229507446, 'learning_rate': 4.2437722419928824e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0747, 'grad_norm': 0.11859090626239777, 'learning_rate': 4.199288256227758e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0035, 'grad_norm': 0.07505851238965988, 'learning_rate': 4.154804270462634e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0943, 'grad_norm': 0.09809849411249161, 'learning_rate': 4.1103202846975093e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0044, 'grad_norm': 0.33809080719947815, 'learning_rate': 4.065836298932384e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0852, 'grad_norm': 4.7380876541137695, 'learning_rate': 4.02135231316726e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0732, 'grad_norm': 0.11076521873474121, 'learning_rate': 3.9768683274021356e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0385, 'grad_norm': 0.14960674941539764, 'learning_rate': 3.932384341637011e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0471, 'grad_norm': 0.04152407497167587, 'learning_rate': 3.887900355871886e-05, 'epoch': 0.44}\n",
      "{'loss': 0.133, 'grad_norm': 0.1413910984992981, 'learning_rate': 3.843416370106761e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0561, 'grad_norm': 0.19877134263515472, 'learning_rate': 3.7989323843416376e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0322, 'grad_norm': 3.292024850845337, 'learning_rate': 3.7544483985765126e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0228, 'grad_norm': 0.1330869197845459, 'learning_rate': 3.709964412811388e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0453, 'grad_norm': 0.030897140502929688, 'learning_rate': 3.665480427046263e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0057, 'grad_norm': 0.020217882469296455, 'learning_rate': 3.6209964412811396e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0849, 'grad_norm': 0.02044801600277424, 'learning_rate': 3.5765124555160145e-05, 'epoch': 0.57}\n",
      "{'loss': 0.074, 'grad_norm': 0.06683153659105301, 'learning_rate': 3.53202846975089e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0246, 'grad_norm': 0.4303075075149536, 'learning_rate': 3.487544483985765e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0395, 'grad_norm': 0.07886217534542084, 'learning_rate': 3.44306049822064e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0634, 'grad_norm': 0.06522908806800842, 'learning_rate': 3.3985765124555165e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0724, 'grad_norm': 0.09307696670293808, 'learning_rate': 3.3540925266903915e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0099, 'grad_norm': 0.0496886782348156, 'learning_rate': 3.309608540925267e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0225, 'grad_norm': 0.04912276193499565, 'learning_rate': 3.265124555160142e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0116, 'grad_norm': 0.014812037348747253, 'learning_rate': 3.2206405693950184e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0486, 'grad_norm': 0.030307944864034653, 'learning_rate': 3.1761565836298934e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0021, 'grad_norm': 0.014974735677242279, 'learning_rate': 3.1316725978647684e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0479, 'grad_norm': 2.60158371925354, 'learning_rate': 3.087188612099644e-05, 'epoch': 0.77}\n",
      "{'loss': 0.0811, 'grad_norm': 0.10581260174512863, 'learning_rate': 3.04270462633452e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0037, 'grad_norm': 0.36473172903060913, 'learning_rate': 2.9982206405693954e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0703, 'grad_norm': 0.06076465919613838, 'learning_rate': 2.9537366548042704e-05, 'epoch': 0.82}\n",
      "{'loss': 0.0019, 'grad_norm': 0.022675400599837303, 'learning_rate': 2.9092526690391457e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0013, 'grad_norm': 0.04546447470784187, 'learning_rate': 2.8647686832740217e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0828, 'grad_norm': 0.11920282989740372, 'learning_rate': 2.820284697508897e-05, 'epoch': 0.87}\n",
      "{'loss': 0.0524, 'grad_norm': 0.054048798978328705, 'learning_rate': 2.7758007117437723e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0988, 'grad_norm': 0.04079713672399521, 'learning_rate': 2.7313167259786476e-05, 'epoch': 0.91}\n",
      "{'loss': 0.1212, 'grad_norm': 83.7675552368164, 'learning_rate': 2.6868327402135236e-05, 'epoch': 0.93}\n",
      "{'loss': 0.0389, 'grad_norm': 0.1573581099510193, 'learning_rate': 2.642348754448399e-05, 'epoch': 0.94}\n",
      "{'loss': 0.0366, 'grad_norm': 0.05184214934706688, 'learning_rate': 2.597864768683274e-05, 'epoch': 0.96}\n",
      "{'loss': 0.025, 'grad_norm': 0.05717688426375389, 'learning_rate': 2.5533807829181493e-05, 'epoch': 0.98}\n",
      "{'loss': 0.0049, 'grad_norm': 0.14116404950618744, 'learning_rate': 2.5088967971530253e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a47523cf6c4494a3b59c294976795b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.043800923973321915, 'eval_runtime': 2.1953, 'eval_samples_per_second': 512.009, 'eval_steps_per_second': 64.229, 'epoch': 1.0}\n",
      "{'loss': 0.032, 'grad_norm': 0.07249152660369873, 'learning_rate': 2.4644128113879006e-05, 'epoch': 1.01}\n",
      "{'loss': 0.0293, 'grad_norm': 0.009911589324474335, 'learning_rate': 2.419928825622776e-05, 'epoch': 1.03}\n",
      "{'loss': 0.0016, 'grad_norm': 0.018290527164936066, 'learning_rate': 2.3754448398576516e-05, 'epoch': 1.05}\n",
      "{'loss': 0.0012, 'grad_norm': 0.03366841748356819, 'learning_rate': 2.330960854092527e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0339, 'grad_norm': 0.028940701857209206, 'learning_rate': 2.2864768683274025e-05, 'epoch': 1.09}\n",
      "{'loss': 0.001, 'grad_norm': 0.01527597475796938, 'learning_rate': 2.2419928825622775e-05, 'epoch': 1.1}\n",
      "{'loss': 0.0118, 'grad_norm': 0.024272875860333443, 'learning_rate': 2.197508896797153e-05, 'epoch': 1.12}\n",
      "{'loss': 0.0011, 'grad_norm': 0.2054251730442047, 'learning_rate': 2.1530249110320285e-05, 'epoch': 1.14}\n",
      "{'loss': 0.0018, 'grad_norm': 0.014270532876253128, 'learning_rate': 2.1085409252669038e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0464, 'grad_norm': 0.011838500387966633, 'learning_rate': 2.0640569395017795e-05, 'epoch': 1.17}\n",
      "{'loss': 0.0007, 'grad_norm': 0.01676647923886776, 'learning_rate': 2.0195729537366548e-05, 'epoch': 1.19}\n",
      "{'loss': 0.0007, 'grad_norm': 0.019936708733439445, 'learning_rate': 1.9750889679715305e-05, 'epoch': 1.21}\n",
      "{'loss': 0.0005, 'grad_norm': 0.017539145424962044, 'learning_rate': 1.9306049822064058e-05, 'epoch': 1.23}\n",
      "{'loss': 0.0368, 'grad_norm': 0.4079750180244446, 'learning_rate': 1.8861209964412814e-05, 'epoch': 1.25}\n",
      "{'loss': 0.0783, 'grad_norm': 8.564101219177246, 'learning_rate': 1.8416370106761564e-05, 'epoch': 1.26}\n",
      "{'loss': 0.0922, 'grad_norm': 0.041739482432603836, 'learning_rate': 1.797153024911032e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0216, 'grad_norm': 0.6249907612800598, 'learning_rate': 1.7526690391459074e-05, 'epoch': 1.3}\n",
      "{'loss': 0.035, 'grad_norm': 0.023585792630910873, 'learning_rate': 1.708185053380783e-05, 'epoch': 1.32}\n",
      "{'loss': 0.0571, 'grad_norm': 0.05892224609851837, 'learning_rate': 1.6637010676156584e-05, 'epoch': 1.33}\n",
      "{'loss': 0.002, 'grad_norm': 0.04554970562458038, 'learning_rate': 1.619217081850534e-05, 'epoch': 1.35}\n",
      "{'loss': 0.0306, 'grad_norm': 0.0919945016503334, 'learning_rate': 1.5747330960854093e-05, 'epoch': 1.37}\n",
      "{'loss': 0.0299, 'grad_norm': 0.05335451290011406, 'learning_rate': 1.530249110320285e-05, 'epoch': 1.39}\n",
      "{'loss': 0.0385, 'grad_norm': 0.011988483369350433, 'learning_rate': 1.4857651245551602e-05, 'epoch': 1.41}\n",
      "{'loss': 0.0021, 'grad_norm': 0.0999835953116417, 'learning_rate': 1.4412811387900358e-05, 'epoch': 1.42}\n",
      "{'loss': 0.0891, 'grad_norm': 0.07885521650314331, 'learning_rate': 1.396797153024911e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0536, 'grad_norm': 16.25516700744629, 'learning_rate': 1.3523131672597866e-05, 'epoch': 1.46}\n",
      "{'loss': 0.0564, 'grad_norm': 0.39360329508781433, 'learning_rate': 1.307829181494662e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0137, 'grad_norm': 0.15790247917175293, 'learning_rate': 1.2633451957295376e-05, 'epoch': 1.49}\n",
      "{'loss': 0.0034, 'grad_norm': 0.05256427824497223, 'learning_rate': 1.2188612099644127e-05, 'epoch': 1.51}\n",
      "{'loss': 0.0329, 'grad_norm': 0.10614681243896484, 'learning_rate': 1.1743772241992882e-05, 'epoch': 1.53}\n",
      "{'loss': 0.002, 'grad_norm': 0.051440149545669556, 'learning_rate': 1.1298932384341637e-05, 'epoch': 1.55}\n",
      "{'loss': 0.0298, 'grad_norm': 0.06454792618751526, 'learning_rate': 1.0854092526690392e-05, 'epoch': 1.57}\n",
      "{'loss': 0.0287, 'grad_norm': 0.08542792499065399, 'learning_rate': 1.0409252669039145e-05, 'epoch': 1.58}\n",
      "{'loss': 0.0025, 'grad_norm': 0.08748582005500793, 'learning_rate': 9.9644128113879e-06, 'epoch': 1.6}\n",
      "{'loss': 0.0022, 'grad_norm': 0.0053695738315582275, 'learning_rate': 9.519572953736655e-06, 'epoch': 1.62}\n",
      "{'loss': 0.0022, 'grad_norm': 0.06496679782867432, 'learning_rate': 9.07473309608541e-06, 'epoch': 1.64}\n",
      "{'loss': 0.001, 'grad_norm': 0.03656115382909775, 'learning_rate': 8.629893238434163e-06, 'epoch': 1.65}\n",
      "{'loss': 0.0022, 'grad_norm': 0.015118430368602276, 'learning_rate': 8.185053380782918e-06, 'epoch': 1.67}\n",
      "{'loss': 0.0318, 'grad_norm': 0.030087478458881378, 'learning_rate': 7.740213523131673e-06, 'epoch': 1.69}\n",
      "{'loss': 0.0013, 'grad_norm': 0.017962349578738213, 'learning_rate': 7.295373665480428e-06, 'epoch': 1.71}\n",
      "{'loss': 0.0011, 'grad_norm': 0.018246527761220932, 'learning_rate': 6.850533807829182e-06, 'epoch': 1.73}\n",
      "{'loss': 0.032, 'grad_norm': 0.03768930956721306, 'learning_rate': 6.405693950177937e-06, 'epoch': 1.74}\n",
      "{'loss': 0.006, 'grad_norm': 0.004165408667176962, 'learning_rate': 5.960854092526691e-06, 'epoch': 1.76}\n",
      "{'loss': 0.0014, 'grad_norm': 0.04529720917344093, 'learning_rate': 5.516014234875446e-06, 'epoch': 1.78}\n",
      "{'loss': 0.0319, 'grad_norm': 0.030397040769457817, 'learning_rate': 5.0711743772242e-06, 'epoch': 1.8}\n",
      "{'loss': 0.001, 'grad_norm': 0.031779222190380096, 'learning_rate': 4.626334519572954e-06, 'epoch': 1.81}\n",
      "{'loss': 0.0009, 'grad_norm': 0.012989121489226818, 'learning_rate': 4.181494661921708e-06, 'epoch': 1.83}\n",
      "{'loss': 0.0012, 'grad_norm': 0.9619288444519043, 'learning_rate': 3.7366548042704624e-06, 'epoch': 1.85}\n",
      "{'loss': 0.0213, 'grad_norm': 0.015143459662795067, 'learning_rate': 3.291814946619217e-06, 'epoch': 1.87}\n",
      "{'loss': 0.0288, 'grad_norm': 0.02725062146782875, 'learning_rate': 2.8469750889679713e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0012, 'grad_norm': 0.01988103799521923, 'learning_rate': 2.402135231316726e-06, 'epoch': 1.9}\n",
      "{'loss': 0.0008, 'grad_norm': 0.024987882003188133, 'learning_rate': 1.9572953736654803e-06, 'epoch': 1.92}\n",
      "{'loss': 0.0663, 'grad_norm': 0.022842366248369217, 'learning_rate': 1.512455516014235e-06, 'epoch': 1.94}\n",
      "{'loss': 0.0343, 'grad_norm': 0.017530396580696106, 'learning_rate': 1.0676156583629894e-06, 'epoch': 1.96}\n",
      "{'loss': 0.0007, 'grad_norm': 0.02568255364894867, 'learning_rate': 6.227758007117438e-07, 'epoch': 1.98}\n",
      "{'loss': 0.001, 'grad_norm': 0.03143203631043434, 'learning_rate': 1.779359430604982e-07, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f73548a6e364bc99758d9b49159e532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.019009312614798546, 'eval_runtime': 1.8187, 'eval_samples_per_second': 618.017, 'eval_steps_per_second': 77.527, 'epoch': 2.0}\n",
      "{'train_runtime': 158.2675, 'train_samples_per_second': 113.63, 'train_steps_per_second': 7.102, 'train_loss': 0.04885464983294615, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1124, training_loss=0.04885464983294615, metrics={'train_runtime': 158.2675, 'train_samples_per_second': 113.63, 'train_steps_per_second': 7.102, 'total_flos': 184835516390400.0, 'train_loss': 0.04885464983294615, 'epoch': 2.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"bert_model\")\n",
    "# tokenizer.save_pretrained(\"bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
