{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from IPython.display import HTML          \n",
    "import pandas as pd\n",
    "import torch\n",
    "#from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_metric, Dataset\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    th, td {\n",
       "        text-align: left !important;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Left align data in pd tables\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "    th, td {\n",
    "        text-align: left !important;\n",
    "    }\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and clean \n",
    "# Data is from https://www.kaggle.com/datasets/arshkandroo/behavioural-tweets?select=Lonely_Tweets.csv.\n",
    "# Tweepy API was used to scrape twitter for lonely and normal tweets. The quality is okay but \n",
    "# some misclassification. The tweets are already cleaned using the NLTK library according to the\n",
    "# data collectors.\n",
    "\n",
    "df_normal = pd.read_csv('Data/Normal_Tweets.csv.xls')\n",
    "del df_normal['Unnamed: 0']\n",
    "df_normal.columns.values[0] = 'tweet'\n",
    "df_normal['label'] = 0                                  # 0 for normal tweets \n",
    "df_normal['id'] = range(1, len(df_normal) + 1)\n",
    "\n",
    "df_lonely = pd.read_csv('Data/Lonely_Tweets.csv.xls')\n",
    "del df_lonely['Unnamed: 0']\n",
    "df_lonely.columns.values[0] = 'tweet'\n",
    "df_lonely['label'] = 1                                  # 1 for lonely tweets\n",
    "df_lonely['id'] = range(len(df_normal) + 1, len(df_normal) + len(df_lonely) + 1)\n",
    "\n",
    "df = pd.concat([df_normal, df_lonely])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set has 18447 tweets in it.\n",
      "\n",
      "There are 3 variables and they are as follows: \n",
      "tweet    object\n",
      "label     int64\n",
      "id        int64\n",
      "dtype: object\n",
      "\n",
      "The first and last five rows of the table are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>remember hillary email non secure server</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cant avoid demon</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>por fin la pusieron en spotify losing way de f...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kills</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thank introduce important gunsense law make co...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517</th>\n",
       "      <td>love son get paternity test person sex doesnt ...</td>\n",
       "      <td>1</td>\n",
       "      <td>18443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>tell father dont want bother need talk god cau...</td>\n",
       "      <td>1</td>\n",
       "      <td>18444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8519</th>\n",
       "      <td>lrt leave alone finally found need cry love ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>18445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8520</th>\n",
       "      <td>know something dont need one love want want wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>18446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8521</th>\n",
       "      <td>dont need want meet want several moment side</td>\n",
       "      <td>1</td>\n",
       "      <td>18447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  label     id\n",
       "0             remember hillary email non secure server       0      1\n",
       "1                                     cant avoid demon       0      2\n",
       "2     por fin la pusieron en spotify losing way de f...      0      3\n",
       "3                                                kills       0      4\n",
       "4     thank introduce important gunsense law make co...      0      5\n",
       "8517  love son get paternity test person sex doesnt ...      1  18443\n",
       "8518  tell father dont want bother need talk god cau...      1  18444\n",
       "8519  lrt leave alone finally found need cry love ha...      1  18445\n",
       "8520  know something dont need one love want want wa...      1  18446\n",
       "8521      dont need want meet want several moment side       1  18447"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display summary data\n",
    "print(f\"The data set has {len(df)} tweets in it.\")\n",
    "print()\n",
    "\n",
    "print(f\"There are {df.shape[1]} variables and they are as follows: \")\n",
    "print(df.dtypes)\n",
    "print()\n",
    "\n",
    "print(\"The first and last five rows of the table are:\")\n",
    "pd.concat([df.head(), df.tail()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation set\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df.tweet.tolist()\n",
    "train_labels = train_df.label.tolist()\n",
    "\n",
    "labels = torch.tensor(train_labels)\n",
    "\n",
    "encoded_inputs = tokenizer(\n",
    "    train_texts,\n",
    "    add_special_tokens=True,\n",
    "    truncation=True,\n",
    "    max_length=20,\n",
    "    padding='max_length',\n",
    "    return_attention_mask=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "input_ids = encoded_inputs[\"input_ids\"]\n",
    "attention_masks = encoded_inputs[\"attention_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dict = {\n",
    "    'input_ids': input_ids,\n",
    "    'attention_mask': attention_masks,\n",
    "    'labels': labels\n",
    "}\n",
    "\n",
    "train_data_dict = {key: tensor.to(\"mps\") for key, tensor in train_data_dict.items()}\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Create a Dataset object\n",
    "train_dataset = Dataset.from_dict(train_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    disable_tqdm=True,  \n",
    "    log_level=\"error\" \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,  \n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,  \n",
    "    # Optionally add a validation dataset\n",
    "    # eval_dataset=validation_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6791, 'grad_norm': 3.446047782897949, 'learning_rate': 4.945828819068256e-05, 'epoch': 0.010834236186348862}\n",
      "{'loss': 0.5427, 'grad_norm': 6.040877819061279, 'learning_rate': 4.891657638136511e-05, 'epoch': 0.021668472372697724}\n",
      "{'loss': 0.4229, 'grad_norm': 3.940645456314087, 'learning_rate': 4.837486457204768e-05, 'epoch': 0.032502708559046585}\n",
      "{'loss': 0.3626, 'grad_norm': 8.920709609985352, 'learning_rate': 4.7833152762730235e-05, 'epoch': 0.04333694474539545}\n",
      "{'loss': 0.3025, 'grad_norm': 6.809895992279053, 'learning_rate': 4.7291440953412786e-05, 'epoch': 0.05417118093174431}\n",
      "{'loss': 0.3584, 'grad_norm': 4.547197341918945, 'learning_rate': 4.6749729144095344e-05, 'epoch': 0.06500541711809317}\n",
      "{'loss': 0.3535, 'grad_norm': 5.68408727645874, 'learning_rate': 4.6208017334777896e-05, 'epoch': 0.07583965330444203}\n",
      "{'loss': 0.2832, 'grad_norm': 1.9386407136917114, 'learning_rate': 4.5666305525460454e-05, 'epoch': 0.0866738894907909}\n",
      "{'loss': 0.2697, 'grad_norm': 9.288897514343262, 'learning_rate': 4.512459371614302e-05, 'epoch': 0.09750812567713976}\n",
      "{'loss': 0.2732, 'grad_norm': 4.213076591491699, 'learning_rate': 4.458288190682557e-05, 'epoch': 0.10834236186348863}\n",
      "{'loss': 0.3285, 'grad_norm': 2.7021896839141846, 'learning_rate': 4.404117009750813e-05, 'epoch': 0.11917659804983749}\n",
      "{'loss': 0.3339, 'grad_norm': 8.010177612304688, 'learning_rate': 4.3499458288190686e-05, 'epoch': 0.13001083423618634}\n",
      "{'loss': 0.2661, 'grad_norm': 2.0164601802825928, 'learning_rate': 4.295774647887324e-05, 'epoch': 0.14084507042253522}\n",
      "{'loss': 0.2768, 'grad_norm': 5.709052085876465, 'learning_rate': 4.2416034669555795e-05, 'epoch': 0.15167930660888407}\n",
      "{'loss': 0.2219, 'grad_norm': 1.3548970222473145, 'learning_rate': 4.187432286023836e-05, 'epoch': 0.16251354279523295}\n",
      "{'loss': 0.1525, 'grad_norm': 1.696471095085144, 'learning_rate': 4.133261105092091e-05, 'epoch': 0.1733477789815818}\n",
      "{'loss': 0.4708, 'grad_norm': 8.731159210205078, 'learning_rate': 4.079089924160347e-05, 'epoch': 0.18418201516793067}\n",
      "{'loss': 0.3864, 'grad_norm': 2.151092052459717, 'learning_rate': 4.024918743228603e-05, 'epoch': 0.19501625135427952}\n",
      "{'loss': 0.3594, 'grad_norm': 4.585083961486816, 'learning_rate': 3.970747562296858e-05, 'epoch': 0.20585048754062837}\n",
      "{'loss': 0.315, 'grad_norm': 4.514008045196533, 'learning_rate': 3.916576381365114e-05, 'epoch': 0.21668472372697725}\n",
      "{'loss': 0.3016, 'grad_norm': 4.262867450714111, 'learning_rate': 3.8624052004333695e-05, 'epoch': 0.2275189599133261}\n",
      "{'loss': 0.2692, 'grad_norm': 4.556449890136719, 'learning_rate': 3.8082340195016254e-05, 'epoch': 0.23835319609967498}\n",
      "{'loss': 0.2894, 'grad_norm': 1.9715619087219238, 'learning_rate': 3.754062838569881e-05, 'epoch': 0.24918743228602383}\n",
      "{'loss': 0.1988, 'grad_norm': 1.226518154144287, 'learning_rate': 3.699891657638136e-05, 'epoch': 0.2600216684723727}\n",
      "{'loss': 0.3158, 'grad_norm': 28.35901641845703, 'learning_rate': 3.645720476706392e-05, 'epoch': 0.27085590465872156}\n",
      "{'loss': 0.3034, 'grad_norm': 0.9148426055908203, 'learning_rate': 3.5915492957746486e-05, 'epoch': 0.28169014084507044}\n",
      "{'loss': 0.3234, 'grad_norm': 14.613770484924316, 'learning_rate': 3.537378114842904e-05, 'epoch': 0.29252437703141926}\n",
      "{'loss': 0.2657, 'grad_norm': 1.5388933420181274, 'learning_rate': 3.4832069339111595e-05, 'epoch': 0.30335861321776814}\n",
      "{'loss': 0.2841, 'grad_norm': 13.37617015838623, 'learning_rate': 3.4290357529794153e-05, 'epoch': 0.314192849404117}\n",
      "{'loss': 0.2021, 'grad_norm': 4.044360637664795, 'learning_rate': 3.3748645720476705e-05, 'epoch': 0.3250270855904659}\n",
      "{'loss': 0.2938, 'grad_norm': 3.8652045726776123, 'learning_rate': 3.320693391115926e-05, 'epoch': 0.3358613217768147}\n",
      "{'loss': 0.2426, 'grad_norm': 2.509552478790283, 'learning_rate': 3.266522210184182e-05, 'epoch': 0.3466955579631636}\n",
      "{'loss': 0.2034, 'grad_norm': 9.149678230285645, 'learning_rate': 3.212351029252438e-05, 'epoch': 0.35752979414951247}\n",
      "{'loss': 0.2252, 'grad_norm': 12.068807601928711, 'learning_rate': 3.158179848320694e-05, 'epoch': 0.36836403033586135}\n",
      "{'loss': 0.2662, 'grad_norm': 7.96839714050293, 'learning_rate': 3.104008667388949e-05, 'epoch': 0.37919826652221017}\n",
      "{'loss': 0.1478, 'grad_norm': 1.504360556602478, 'learning_rate': 3.049837486457205e-05, 'epoch': 0.39003250270855905}\n",
      "{'loss': 0.1435, 'grad_norm': 6.76714563369751, 'learning_rate': 2.9956663055254608e-05, 'epoch': 0.4008667388949079}\n",
      "{'loss': 0.238, 'grad_norm': 0.5810659527778625, 'learning_rate': 2.9414951245937163e-05, 'epoch': 0.41170097508125675}\n",
      "{'loss': 0.3316, 'grad_norm': 3.9760262966156006, 'learning_rate': 2.887323943661972e-05, 'epoch': 0.4225352112676056}\n",
      "{'loss': 0.2434, 'grad_norm': 1.617132306098938, 'learning_rate': 2.833152762730228e-05, 'epoch': 0.4333694474539545}\n",
      "{'loss': 0.2729, 'grad_norm': 2.6148266792297363, 'learning_rate': 2.7789815817984834e-05, 'epoch': 0.4442036836403034}\n",
      "{'loss': 0.1378, 'grad_norm': 5.052628040313721, 'learning_rate': 2.7248104008667392e-05, 'epoch': 0.4550379198266522}\n",
      "{'loss': 0.2528, 'grad_norm': 5.180591583251953, 'learning_rate': 2.6706392199349943e-05, 'epoch': 0.4658721560130011}\n",
      "{'loss': 0.1095, 'grad_norm': 6.2436957359313965, 'learning_rate': 2.6164680390032505e-05, 'epoch': 0.47670639219934996}\n",
      "{'loss': 0.2903, 'grad_norm': 4.368600368499756, 'learning_rate': 2.5622968580715063e-05, 'epoch': 0.4875406283856988}\n",
      "{'loss': 0.1718, 'grad_norm': 1.35610032081604, 'learning_rate': 2.5081256771397614e-05, 'epoch': 0.49837486457204766}\n",
      "{'loss': 0.2414, 'grad_norm': 5.992783069610596, 'learning_rate': 2.4539544962080176e-05, 'epoch': 0.5092091007583965}\n",
      "{'loss': 0.2609, 'grad_norm': 4.515976905822754, 'learning_rate': 2.399783315276273e-05, 'epoch': 0.5200433369447454}\n",
      "{'loss': 0.3513, 'grad_norm': 7.385351181030273, 'learning_rate': 2.345612134344529e-05, 'epoch': 0.5308775731310943}\n",
      "{'loss': 0.256, 'grad_norm': 2.3192343711853027, 'learning_rate': 2.2914409534127847e-05, 'epoch': 0.5417118093174431}\n",
      "{'loss': 0.2287, 'grad_norm': 4.944661617279053, 'learning_rate': 2.23726977248104e-05, 'epoch': 0.5525460455037919}\n",
      "{'loss': 0.2952, 'grad_norm': 1.7799054384231567, 'learning_rate': 2.1830985915492956e-05, 'epoch': 0.5633802816901409}\n",
      "{'loss': 0.2624, 'grad_norm': 2.3613293170928955, 'learning_rate': 2.1289274106175517e-05, 'epoch': 0.5742145178764897}\n",
      "{'loss': 0.2963, 'grad_norm': 3.283480167388916, 'learning_rate': 2.0747562296858072e-05, 'epoch': 0.5850487540628385}\n",
      "{'loss': 0.3943, 'grad_norm': 1.053147315979004, 'learning_rate': 2.0205850487540627e-05, 'epoch': 0.5958829902491874}\n",
      "{'loss': 0.1957, 'grad_norm': 3.135237693786621, 'learning_rate': 1.966413867822319e-05, 'epoch': 0.6067172264355363}\n",
      "{'loss': 0.2725, 'grad_norm': 2.7419731616973877, 'learning_rate': 1.9122426868905743e-05, 'epoch': 0.6175514626218852}\n",
      "{'loss': 0.2266, 'grad_norm': 5.589084625244141, 'learning_rate': 1.85807150595883e-05, 'epoch': 0.628385698808234}\n",
      "{'loss': 0.1777, 'grad_norm': 1.3422170877456665, 'learning_rate': 1.8039003250270856e-05, 'epoch': 0.6392199349945829}\n",
      "{'loss': 0.2075, 'grad_norm': 3.3376617431640625, 'learning_rate': 1.7497291440953414e-05, 'epoch': 0.6500541711809318}\n",
      "{'loss': 0.1529, 'grad_norm': 1.3555641174316406, 'learning_rate': 1.6955579631635972e-05, 'epoch': 0.6608884073672806}\n",
      "{'loss': 0.2424, 'grad_norm': 1.6781597137451172, 'learning_rate': 1.6413867822318527e-05, 'epoch': 0.6717226435536294}\n",
      "{'loss': 0.2278, 'grad_norm': 2.5018467903137207, 'learning_rate': 1.5872156013001085e-05, 'epoch': 0.6825568797399784}\n",
      "{'loss': 0.2129, 'grad_norm': 0.3245178163051605, 'learning_rate': 1.5330444203683643e-05, 'epoch': 0.6933911159263272}\n",
      "{'loss': 0.4093, 'grad_norm': 1.5366178750991821, 'learning_rate': 1.4788732394366198e-05, 'epoch': 0.704225352112676}\n",
      "{'loss': 0.1553, 'grad_norm': 1.2029179334640503, 'learning_rate': 1.4247020585048754e-05, 'epoch': 0.7150595882990249}\n",
      "{'loss': 0.2234, 'grad_norm': 2.509612560272217, 'learning_rate': 1.3705308775731312e-05, 'epoch': 0.7258938244853738}\n",
      "{'loss': 0.1788, 'grad_norm': 16.49580192565918, 'learning_rate': 1.3163596966413869e-05, 'epoch': 0.7367280606717227}\n",
      "{'loss': 0.1471, 'grad_norm': 2.7340004444122314, 'learning_rate': 1.2621885157096425e-05, 'epoch': 0.7475622968580715}\n",
      "{'loss': 0.2282, 'grad_norm': 1.4804939031600952, 'learning_rate': 1.2080173347778981e-05, 'epoch': 0.7583965330444203}\n",
      "{'loss': 0.2565, 'grad_norm': 9.381120681762695, 'learning_rate': 1.153846153846154e-05, 'epoch': 0.7692307692307693}\n",
      "{'loss': 0.2041, 'grad_norm': 11.323684692382812, 'learning_rate': 1.0996749729144096e-05, 'epoch': 0.7800650054171181}\n",
      "{'loss': 0.2402, 'grad_norm': 10.958954811096191, 'learning_rate': 1.0455037919826654e-05, 'epoch': 0.7908992416034669}\n",
      "{'loss': 0.2272, 'grad_norm': 9.949512481689453, 'learning_rate': 9.913326110509209e-06, 'epoch': 0.8017334777898159}\n",
      "{'loss': 0.1413, 'grad_norm': 1.4714326858520508, 'learning_rate': 9.371614301191767e-06, 'epoch': 0.8125677139761647}\n",
      "{'loss': 0.2451, 'grad_norm': 0.9462462663650513, 'learning_rate': 8.829902491874323e-06, 'epoch': 0.8234019501625135}\n",
      "{'loss': 0.1872, 'grad_norm': 3.3695802688598633, 'learning_rate': 8.28819068255688e-06, 'epoch': 0.8342361863488624}\n",
      "{'loss': 0.1836, 'grad_norm': 1.0059973001480103, 'learning_rate': 7.746478873239436e-06, 'epoch': 0.8450704225352113}\n",
      "{'loss': 0.1783, 'grad_norm': 1.8709272146224976, 'learning_rate': 7.204767063921994e-06, 'epoch': 0.8559046587215602}\n",
      "{'loss': 0.1576, 'grad_norm': 4.275947570800781, 'learning_rate': 6.6630552546045514e-06, 'epoch': 0.866738894907909}\n",
      "{'loss': 0.2841, 'grad_norm': 3.016775608062744, 'learning_rate': 6.121343445287107e-06, 'epoch': 0.8775731310942578}\n",
      "{'loss': 0.1951, 'grad_norm': 2.187735080718994, 'learning_rate': 5.579631635969664e-06, 'epoch': 0.8884073672806068}\n",
      "{'loss': 0.1733, 'grad_norm': 3.410102367401123, 'learning_rate': 5.037919826652221e-06, 'epoch': 0.8992416034669556}\n",
      "{'loss': 0.1275, 'grad_norm': 2.1486759185791016, 'learning_rate': 4.496208017334779e-06, 'epoch': 0.9100758396533044}\n",
      "{'loss': 0.1915, 'grad_norm': 1.1823376417160034, 'learning_rate': 3.954496208017335e-06, 'epoch': 0.9209100758396533}\n",
      "{'loss': 0.3214, 'grad_norm': 10.437549591064453, 'learning_rate': 3.412784398699892e-06, 'epoch': 0.9317443120260022}\n",
      "{'loss': 0.2801, 'grad_norm': 8.283610343933105, 'learning_rate': 2.871072589382449e-06, 'epoch': 0.942578548212351}\n",
      "{'loss': 0.1869, 'grad_norm': 7.264713287353516, 'learning_rate': 2.3293607800650057e-06, 'epoch': 0.9534127843986999}\n",
      "{'loss': 0.0912, 'grad_norm': 0.6224668622016907, 'learning_rate': 1.7876489707475623e-06, 'epoch': 0.9642470205850487}\n",
      "{'loss': 0.2663, 'grad_norm': 1.9615283012390137, 'learning_rate': 1.2459371614301193e-06, 'epoch': 0.9750812567713976}\n",
      "{'loss': 0.1466, 'grad_norm': 2.401064157485962, 'learning_rate': 7.042253521126761e-07, 'epoch': 0.9859154929577465}\n",
      "{'loss': 0.293, 'grad_norm': 1.8570232391357422, 'learning_rate': 1.6251354279523294e-07, 'epoch': 0.9967497291440953}\n",
      "{'train_runtime': 125.2839, 'train_samples_per_second': 117.789, 'train_steps_per_second': 7.367, 'train_loss': 0.25718017708699853, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=923, training_loss=0.25718017708699853, metrics={'train_runtime': 125.2839, 'train_samples_per_second': 117.789, 'train_steps_per_second': 7.367, 'train_loss': 0.25718017708699853, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"bert_model\")\n",
    "# tokenizer.save_pretrained(\"bert_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
